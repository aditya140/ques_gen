{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:torchtext.data.iterator:The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "WARNING:torchtext.data.iterator:The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "WARNING:torchtext.data.iterator:The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    }
   ],
   "source": [
    "a=dataset.load_dataset(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   2,    2,    2,    2,    2],\n",
      "        [   5,    5,   14,   14,  126],\n",
      "        [ 102,   27,   38,   38,   68],\n",
      "        [  12,  349,   24,  102,   10],\n",
      "        [  10,   15, 2401,   31,   26],\n",
      "        [ 194,  212,   32,    7,   51],\n",
      "        [  70,    4,   22,  251, 1916],\n",
      "        [  18,    3,  787,  101,  122],\n",
      "        [8309,    1,  884,   61,  219],\n",
      "        [   4,    1,   16,   23,   22],\n",
      "        [   3,    1,   12,    6,  125],\n",
      "        [   1,    1,    7, 6933,   20],\n",
      "        [   1,    1,   16,  119, 2312],\n",
      "        [   1,    1,  442,    4,  121],\n",
      "        [   1,    1,   32,    3,    4],\n",
      "        [   1,    1,   11,    1,    3],\n",
      "        [   1,    1,   26,    1,    1],\n",
      "        [   1,    1,  124,    1,    1],\n",
      "        [   1,    1,    8,    1,    1],\n",
      "        [   1,    1,  103,    1,    1],\n",
      "        [   1,    1,  179,    1,    1],\n",
      "        [   1,    1,   30,    1,    1],\n",
      "        [   1,    1, 3014,    1,    1],\n",
      "        [   1,    1,   15,    1,    1],\n",
      "        [   1,    1, 1045,    1,    1],\n",
      "        [   1,    1,    4,    1,    1],\n",
      "        [   1,    1,    3,    1,    1]])\n",
      "tensor([[   2,    2,    2,    2,    2],\n",
      "        [   6,    6,    6,    6,   49],\n",
      "        [  25,   25,   39,   39,   72],\n",
      "        [  12,   33,   13,   13,   14],\n",
      "        [   7,  330, 1030,   25,    8],\n",
      "        [ 218,    4,   32,   36,   31],\n",
      "        [ 168,  139,    7,   76,  171],\n",
      "        [   4,    5,    4,    7,   43],\n",
      "        [ 685,    3,  902,   31, 1201],\n",
      "        [  67,    1,  866,  156,   23],\n",
      "        [  27,    1,    8,  236,   10],\n",
      "        [1664,    1,   12,    4,  232],\n",
      "        [   5,    1,    7, 2450,    4],\n",
      "        [   3,    1,    8,  299,  169],\n",
      "        [   1,    1,  181,    5,    7],\n",
      "        [   1,    1,   10,    3,    8],\n",
      "        [   1,    1,   32,    1,  100],\n",
      "        [   1,    1,    9,    1,    5],\n",
      "        [   1,    1,    8,    1,    3],\n",
      "        [   1,    1,  262,    1,    1],\n",
      "        [   1,    1,   11,    1,    1],\n",
      "        [   1,    1,  601,    1,    1],\n",
      "        [   1,    1,   10,    1,    1],\n",
      "        [   1,    1,    4,    1,    1],\n",
      "        [   1,    1, 1428,    1,    1],\n",
      "        [   1,    1,   37,    1,    1],\n",
      "        [   1,    1,   50,    1,    1],\n",
      "        [   1,    1,   98,    1,    1],\n",
      "        [   1,    1,  146,    1,    1],\n",
      "        [   1,    1,    5,    1,    1],\n",
      "        [   1,    1,    3,    1,    1]])\n",
      "<torchtext.datasets.translation.Multi30k object at 0x7f15bef02c10>\n",
      "['batch_size', 'dataset', 'fields', 'input_fields', 'target_fields', 'src', 'trg', '__module__', '__doc__', '__init__', 'fromvars', '__repr__', '__str__', '__len__', '_get_field_values', '__iter__', '__dict__', '__weakref__', '__hash__', '__getattribute__', '__setattr__', '__delattr__', '__lt__', '__le__', '__eq__', '__ne__', '__gt__', '__ge__', '__new__', '__reduce_ex__', '__reduce__', '__subclasshook__', '__init_subclass__', '__format__', '__sizeof__', '__dir__', '__class__']\n"
     ]
    }
   ],
   "source": [
    "for i in a:\n",
    "    for j in i:\n",
    "        print(j.src)\n",
    "        print(j.trg)\n",
    "        print(j.dataset)\n",
    "        print(j.__dir__())\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_en = spacy.load('en')\n",
    "def tokenize_en(text):\n",
    "        return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=tokenize_en(\"Hello hwoa are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field, BucketIterator,TabularDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_lang = Field(tokenize=tokenize_en, init_token='<sos>', eos_token='<eos>')\n",
    "opt_lang = Field(tokenize=tokenize_en, init_token='<sos>', eos_token='<eos>')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fields = [('ans', inp_lang), ('que', opt_lang)]\n",
    "train,val = TabularDataset.splits(path='./.data/', train='train.csv', validation='val.csv', format='csv', fields=data_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_lang.build_vocab(train,val)\n",
    "opt_lang.build_vocab(train,val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1969,  615, 3390, 3390, 2009, 2148, 1969]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.read_csv(\".data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82767, 4)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchtext.vocab.Vocab"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "qgen=dataset.QGenDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Failure :  0\n",
      "Load Failure :  0\n",
      "Load Failure :  0\n",
      "Load Failure :  43498\n",
      "Load Failure :  5945\n"
     ]
    }
   ],
   "source": [
    "qgen._fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.42B.300d.zip: 1.88GB [14:33, 2.15MB/s]                            \n",
      "100%|█████████▉| 1917372/1917494 [03:21<00:00, 10378.43it/s]"
     ]
    }
   ],
   "source": [
    "inp_lang.vocab.load_vectors(\"glove.42B.300d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.1457e-01, -5.1367e-01,  3.2210e-01,  5.4995e-02,  5.5951e-01,\n",
       "        -2.0149e-02, -1.6463e+00, -2.1642e-01, -1.8585e-01, -7.6916e-01,\n",
       "        -1.0133e-02, -6.2154e-02,  3.0545e-01, -3.9373e-01, -4.7257e-01,\n",
       "        -4.0850e-01,  1.1824e-01, -3.1163e-01, -5.0630e-03,  4.1088e-01,\n",
       "         3.3824e-01,  5.2521e-02,  3.0271e-01,  3.5258e-01, -1.7552e-01,\n",
       "        -4.7280e-04,  2.3839e-02,  4.5845e-01,  2.5750e-01,  3.3118e-02,\n",
       "         1.2671e-01, -1.9215e-01,  3.6240e-01, -7.1027e-02,  2.6915e-01,\n",
       "        -2.0077e-01,  7.4150e-02,  1.0814e-01,  2.2891e-01,  1.6823e-01,\n",
       "         1.1329e-01,  1.7791e-01,  2.3952e-02, -1.4993e-01, -1.2613e-01,\n",
       "        -9.8029e-02, -3.0535e-01, -9.4352e-02,  5.1821e-01, -4.3049e-01,\n",
       "        -2.8761e-01,  2.7622e-02,  2.0184e-01,  2.2188e-02,  1.4464e-01,\n",
       "         2.8736e-01,  3.3884e-01, -1.3414e-01,  9.7698e-01,  2.5356e-01,\n",
       "        -3.3928e-01,  1.4415e-03,  1.9131e-02, -3.9172e-01,  4.5803e-01,\n",
       "         5.1720e-01, -3.4131e-01,  6.8218e-02, -1.2524e-01,  7.9428e-02,\n",
       "         3.0650e-03,  4.0055e-01, -1.8837e-01,  3.9316e-01, -7.2131e-02,\n",
       "        -4.1886e-02,  1.8386e-01,  3.3677e-01,  1.7619e-01, -1.4437e-01,\n",
       "         5.4490e-01,  1.9301e-02, -3.1539e-01, -4.8676e-01,  2.0211e-01,\n",
       "         3.4774e-01,  3.0520e-01,  3.7232e-01, -3.1156e-01,  9.6372e-01,\n",
       "        -5.4087e-01, -1.3478e-01,  1.3174e-01, -2.3045e-01, -3.5977e-01,\n",
       "        -3.4047e-01, -8.5660e-01,  3.8469e-02,  1.5613e-01, -2.3571e-03,\n",
       "        -1.2716e-01, -1.5777e-01, -2.8656e-01, -3.3708e-01,  7.1274e-02,\n",
       "         2.5838e-01,  1.4784e-01, -6.3565e-02,  2.3783e-01, -1.8415e-01,\n",
       "        -2.6274e-01, -2.4807e-01, -2.6949e-01,  1.4914e-01, -1.9750e-01,\n",
       "         9.6772e-01,  8.4332e-02,  1.0363e-01,  1.2576e-02, -2.2948e-01,\n",
       "        -1.1784e-01,  9.3359e-03,  5.0288e-01,  7.6850e-01,  4.0112e-01,\n",
       "        -4.5457e-02, -1.4534e-01,  2.5848e-01,  4.5132e-01, -4.1712e-03,\n",
       "        -2.7386e-01,  2.5618e-01, -1.8180e-01, -2.8451e-01, -2.3413e-01,\n",
       "         2.1252e-02,  3.4913e-01, -1.8067e-01, -2.1376e-01,  9.8650e-01,\n",
       "        -4.4107e-01,  3.7352e-01,  1.8654e-01, -3.7053e-02, -1.8040e-01,\n",
       "        -8.8111e-01,  4.6106e-01, -1.3429e-01,  6.1358e-01, -3.9898e-01,\n",
       "        -3.2921e-01,  3.4685e-01,  6.1076e-02,  1.6279e-01,  2.2424e-01,\n",
       "         2.9324e-01,  2.6029e-02, -3.2399e-01,  3.8441e-01,  2.6564e-01,\n",
       "        -7.1761e-02,  1.5462e-01, -6.6879e-01, -2.0571e-01, -1.0013e-01,\n",
       "         5.8422e-01, -6.8078e-02, -7.1236e-02, -1.1905e-01, -3.7294e-01,\n",
       "        -6.2979e-02,  4.0410e-01,  7.1038e-01, -5.0853e-02,  6.1323e-02,\n",
       "         2.0109e-01, -3.5131e-01, -1.2745e-02,  2.2342e-01,  2.6733e-01,\n",
       "        -1.1622e-01, -3.1852e-02,  5.1675e-01, -1.9420e-01,  4.2959e-01,\n",
       "        -1.3590e-01, -8.8158e-02,  1.0419e-01, -7.1527e-03,  1.3783e-01,\n",
       "        -2.5816e-01,  4.2070e-01,  3.2537e-01, -2.3497e-01,  2.4386e-01,\n",
       "         2.0049e-01,  5.8766e-02,  4.7090e-02,  1.3561e-01,  2.0401e-01,\n",
       "         6.5540e-03,  1.2348e-01, -2.2109e-01, -2.6404e-01, -3.0941e-01,\n",
       "        -1.0101e-01, -2.7811e-01, -5.6633e-01,  3.4896e-01,  1.9106e-01,\n",
       "         4.0698e-01, -5.8428e-01,  4.1291e-01,  2.7370e-01, -3.9787e-01,\n",
       "        -3.1072e-01,  9.0169e-02,  3.1425e-01, -5.1760e-01,  7.6444e-02,\n",
       "        -1.8985e-01,  2.5566e-02, -9.3965e-02, -4.3337e-02, -2.6947e+00,\n",
       "        -1.3591e-01,  2.0581e-02, -1.3857e-02, -1.9665e-01, -1.1123e-01,\n",
       "        -3.0069e-01,  4.4234e-01, -1.8951e-01,  2.8825e-01, -2.1343e-01,\n",
       "        -8.9844e-02,  2.8515e-01, -4.3214e-02,  1.9722e-01,  4.0769e-01,\n",
       "         1.0127e-01,  1.4557e-01,  5.3141e-02, -8.6166e-02, -1.6809e-02,\n",
       "        -1.6306e-01, -1.4680e-01,  1.7328e-01, -8.2974e-02, -2.0902e-01,\n",
       "         9.0557e-02,  8.6546e-02, -1.1931e-01,  1.5786e-01,  5.9783e-01,\n",
       "        -1.0498e-01,  1.8417e-01,  9.8438e-02,  1.4940e-01, -3.0176e-01,\n",
       "        -2.5345e-01,  3.1119e-01,  4.9875e-02, -4.1381e-01, -4.6658e-01,\n",
       "        -7.8059e-02,  5.4129e-01,  8.9759e-02, -3.1766e-01,  2.1013e-01,\n",
       "        -2.3705e-01, -2.4798e-01, -4.6771e-01, -2.1807e-01, -3.5934e-01,\n",
       "         2.5933e-01, -3.4218e-01,  3.8913e-02, -2.0949e-01, -8.3503e-02,\n",
       "        -2.6685e-01, -7.7295e-02, -3.5916e-01,  8.3617e-02,  3.8130e-01,\n",
       "         3.2644e-01, -4.2112e-01,  3.3763e-01, -1.5886e-01,  4.6525e-01,\n",
       "        -4.8868e-02,  2.8235e-01, -2.3650e-01, -3.6407e-01, -2.6735e-02,\n",
       "        -2.0040e-01, -5.4365e-01, -4.5827e-02, -3.5582e-02, -5.1425e-02])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_lang.vocab.vectors[inp_lang.vocab.stoi[\"hello\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=dataset.QGenDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Failure :  0\n",
      "Load Failure :  0\n",
      "Load Failure :  0\n",
      "Load Failure :  43498\n",
      "Load Failure :  5945\n"
     ]
    }
   ],
   "source": [
    "x._fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Failure :  0\n",
      "Load Failure :  0\n",
      "Load Failure :  0\n",
      "Load Failure :  43498\n",
      "Load Failure :  5945\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "# from torchtext test cases\n",
    "import spacy\n",
    "from torchtext.data import Field, BucketIterator,TabularDataset\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dataset import QGenDataset\n",
    "\n",
    "\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "inp_lang = Field(tokenize=tokenize_en, init_token='<sos>', eos_token='<eos>',unk_token='<unk>')\n",
    "opt_lang = Field(tokenize=tokenize_en, init_token='<sos>', eos_token='<eos>',unk_token='<unk>')\n",
    "\n",
    "dataset=QGenDataset()\n",
    "dataset._fetch_data(normalize=True)\n",
    "dataset.to_csv()\n",
    "\n",
    "data_fields = [('ans', inp_lang), ('que', opt_lang)]\n",
    "train,val = TabularDataset.splits(path='./.data/', train='train.csv', validation='val.csv', format='csv', fields=data_fields)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sequential',\n",
       " 'use_vocab',\n",
       " 'init_token',\n",
       " 'eos_token',\n",
       " 'unk_token',\n",
       " 'fix_length',\n",
       " 'dtype',\n",
       " 'preprocessing',\n",
       " 'postprocessing',\n",
       " 'lower',\n",
       " 'tokenizer_args',\n",
       " 'tokenize',\n",
       " 'include_lengths',\n",
       " 'batch_first',\n",
       " 'pad_token',\n",
       " 'pad_first',\n",
       " 'truncate_first',\n",
       " 'stop_words',\n",
       " 'is_target',\n",
       " '__module__',\n",
       " '__doc__',\n",
       " 'vocab_cls',\n",
       " 'dtypes',\n",
       " 'ignore',\n",
       " '__init__',\n",
       " '__getstate__',\n",
       " '__setstate__',\n",
       " '__hash__',\n",
       " '__eq__',\n",
       " 'preprocess',\n",
       " 'process',\n",
       " 'pad',\n",
       " 'build_vocab',\n",
       " 'numericalize',\n",
       " '__dict__',\n",
       " '__weakref__',\n",
       " '__repr__',\n",
       " '__str__',\n",
       " '__getattribute__',\n",
       " '__setattr__',\n",
       " '__delattr__',\n",
       " '__lt__',\n",
       " '__le__',\n",
       " '__ne__',\n",
       " '__gt__',\n",
       " '__ge__',\n",
       " '__new__',\n",
       " '__reduce_ex__',\n",
       " '__reduce__',\n",
       " '__subclasshook__',\n",
       " '__init_subclass__',\n",
       " '__format__',\n",
       " '__sizeof__',\n",
       " '__dir__',\n",
       " '__class__']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.fields[\"ans\"].__dir__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    }
   ],
   "source": [
    "batch_size=12\n",
    "device=0\n",
    "val_iter = BucketIterator(val, batch_size=batch_size, \\\n",
    "            device=device, repeat=False , sort_key=lambda x: len(x.que), shuffle=True)\n",
    "train_iter = BucketIterator(train, batch_size=batch_size, \\\n",
    "            device=device, repeat=False , sort_key=lambda x: len(x.que), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14607"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_iter.data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Failure :  0\n",
      "Load Failure :  0\n",
      "Load Failure :  0\n",
      "Load Failure :  43498\n",
      "Load Failure :  5945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    }
   ],
   "source": [
    "import dataset\n",
    "a,b,c,d= dataset.load_question_dataset(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74034"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.vocab.vectors.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [06:28, 2.22MB/s]                           \n",
      "100%|█████████▉| 399295/400000 [00:50<00:00, 10339.40it/s]"
     ]
    }
   ],
   "source": [
    "c.vocab.load_vectors('glove.6B.300d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74034"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c.vocab.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.randint(low=1, high=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nov25_18-56-58_python-cpu-high',\n",
       " 'Nov30_04-20-39_python-cpu-high',\n",
       " 'Nov25_20-46-03_python-cpu-high',\n",
       " 'Nov30_04-22-34_python-cpu-high']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"./runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=re.compile(\"fields_([0-9\\-]*)_(\\d*).pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(a,\"fields_10-10-2019_99999.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import test_serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "serve=test_serve.QuestionPredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_paths = glob.glob(\"./models/fields/*\")\n",
    "latest_file = max(field_paths, key=os.path.getctime)\n",
    "pattern=re.compile(\"fields_([0-9\\-]*)_(\\d*).pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('30-11-2019', '42775')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(pattern,latest_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ans': <torchtext.data.field.Field at 0x7f182293de10>,\n",
       " 'que': <torchtext.data.field.Field at 0x7f1807e4a890>}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.data.field.Field at 0x7f182293de10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.fields[\"ans\"]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Failure :  43498\n",
      "Load Failure :  0\n",
      "Load Failure :  0\n",
      "Load Failure :  0\n",
      "Load Failure :  5945\n",
      "Dataframe size: (84792, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained embeddings\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import test_serve\n",
    "serve=test_serve.QuestionPredictor()\n",
    "_,_,test_iter,_,_=datasets.load_question_dataset(batch_size=12,dataset=[\"squad\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_data=pd.read_csv(\".data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()\n",
    "sent=test_data[\"ans\"].values[112]\n",
    "que=test_data[\"que\"].values[112]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import test_serve\n",
    "from evaluate import clean\n",
    "serve=test_serve.QuestionPredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voters approved charter amendments that have lessened the penalties for possession of marijuana (1974), and that aim to protect access to abortion in the city should it ever become illegal in the state of michigan (1990)\n",
      "what amendment approve the approve of the\n",
      "voters in the city approve which kind of amendment ?\n"
     ]
    }
   ],
   "source": [
    "print(sent)\n",
    "print(\" \".join(clean(serve.predict(sent,beam=True,beam_size=6))))\n",
    "print(que)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Failure :  43498\n",
      "Load Failure :  0\n",
      "Load Failure :  0\n",
      "Load Failure :  0\n",
      "Load Failure :  5945\n",
      "Dataframe size: (84792, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained embeddings\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Batch' object has no attribute 'trg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-38ce5f837e96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_question_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"squad\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mstart_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Batch' object has no attribute 'trg'"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "_,_,test_iter,_,_=datasets.load_question_dataset(batch_size=12,dataset=[\"squad\"])\n",
    "batch = next(iter(test_iter))\n",
    "start_token = batch.trg[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_token = batch.ans[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_field=test_iter.dataset.fields[\"ans\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2],\n",
       "        [1723, 1901,  586, 2311, 2170,  260, 4223,  876, 2311, 1209, 1723, 1520,\n",
       "          586,   10,  459, 2311,    5, 2311,   10, 2311, 2559,   10, 1520,  459,\n",
       "         2311, 2114,  463,  586,   10, 1517, 2311,  463,  260, 1520, 1520,  586,\n",
       "         1517, 1723, 2311,    5, 2311, 1520,  260, 1517, 1209, 2311, 1517, 2114,\n",
       "         1520, 1723, 1901, 2559,   10, 1520,  870, 2311, 1729,  260, 1209, 1723,\n",
       "         2311,  144,  311, 2311,  459,  166, 4223,  586, 1209, 2311,   14, 2311,\n",
       "          181,  374, 2311, 5667,  459, 2311,   15, 2311, 2114,  876,  876, 2311,\n",
       "         1723, 1901,  586, 2311,  463, 2114,   10, 1209, 1723, 2311,    5, 2311,\n",
       "           10, 4223, 4223, 2114, 2559,  166, 1517, 2170, 2311, 1723, 1901,  586,\n",
       "         2311,  463,  166, 1723, 2736, 2311,   80, 1209, 2311,  463, 4223,  166,\n",
       "          459,   10, 1723,  586, 2311, 1723, 2114, 2311, 1209, 1723,   10, 2736,\n",
       "         2311, 2559,   10, 1520,  459, 2311,   10, 1517,  870, 2311,  459,  166,\n",
       "         4223,  870, 2311,   10, 4223, 4223, 2311, 2736,  586,   10, 1520],\n",
       "        [   3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
       "            3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
       "            3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
       "            3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
       "            3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
       "            3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
       "            3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
       "            3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
       "            3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
       "            3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
       "            3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
       "            3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
       "            3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_field.(\"the gulf stream , a warm ocean current , runs northward just 15 miles ( 24 km ) off the coast , allowing the city 's climate to stay warm and mild all year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> the gulf stream , a warm ocean current , runs northward just 15 miles ( 24 km ) off the coast , allowing the city 's climate to stay warm and mild all year <eos>\n",
      "<sos> the gulf stream , a warm ocean current , runs northward just 15 miles ( 24 km ) off the coast , allowing the city 's climate to stay warm and mild all year <eos>\n",
      "tensor([[    2],\n",
      "        [    4],\n",
      "        [ 2882],\n",
      "        [ 5498],\n",
      "        [    5],\n",
      "        [   10],\n",
      "        [ 3331],\n",
      "        [  998],\n",
      "        [  451],\n",
      "        [    5],\n",
      "        [ 1960],\n",
      "        [15998],\n",
      "        [  516],\n",
      "        [  446],\n",
      "        [  800],\n",
      "        [   14],\n",
      "        [  823],\n",
      "        [  489],\n",
      "        [   15],\n",
      "        [  485],\n",
      "        [    4],\n",
      "        [  894],\n",
      "        [    5],\n",
      "        [ 1402],\n",
      "        [    4],\n",
      "        [   45],\n",
      "        [   22],\n",
      "        [  707],\n",
      "        [    9],\n",
      "        [ 4058],\n",
      "        [ 3331],\n",
      "        [    7],\n",
      "        [ 4455],\n",
      "        [   60],\n",
      "        [  101],\n",
      "        [    3]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from utils import sequence_to_text,text_to_sequence\n",
    "print(sequence_to_text(batch.ans,ans_field))\n",
    "print(ans_field.init_token+\" \"+sent+\" \"+ans_field.eos_token)\n",
    "source=([ans_field.vocab.stoi[ans_field.init_token]]+text_to_sequence(ans_field.preprocess(sent),ans_field)+[ans_field.vocab.stoi[ans_field.eos_token]])\n",
    "source=[[i] for i in source]\n",
    "print(torch.LongTensor(source))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2],\n",
       "        [    4],\n",
       "        [ 2882],\n",
       "        [ 5498],\n",
       "        [    5],\n",
       "        [   10],\n",
       "        [ 3331],\n",
       "        [  998],\n",
       "        [  451],\n",
       "        [    5],\n",
       "        [ 1960],\n",
       "        [15998],\n",
       "        [  516],\n",
       "        [  446],\n",
       "        [  800],\n",
       "        [   14],\n",
       "        [  823],\n",
       "        [  489],\n",
       "        [   15],\n",
       "        [  485],\n",
       "        [    4],\n",
       "        [  894],\n",
       "        [    5],\n",
       "        [ 1402],\n",
       "        [    4],\n",
       "        [   45],\n",
       "        [   22],\n",
       "        [  707],\n",
       "        [    9],\n",
       "        [ 4058],\n",
       "        [ 3331],\n",
       "        [    7],\n",
       "        [ 4455],\n",
       "        [   60],\n",
       "        [  101],\n",
       "        [    3]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent=\"the gulf stream , a warm ocean current , runs northward just 15 miles ( 24 km ) off the coast , allowing the city 's climate to stay warm and mild all year\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<',\n",
       " 'sos',\n",
       " '>',\n",
       " 'the',\n",
       " 'gulf',\n",
       " 'stream',\n",
       " ',',\n",
       " 'a',\n",
       " 'warm',\n",
       " 'ocean',\n",
       " 'current',\n",
       " ',',\n",
       " 'runs',\n",
       " 'northward',\n",
       " 'just',\n",
       " '15',\n",
       " 'miles',\n",
       " '(',\n",
       " '24',\n",
       " 'km',\n",
       " ')',\n",
       " 'off',\n",
       " 'the',\n",
       " 'coast',\n",
       " ',',\n",
       " 'allowing',\n",
       " 'the',\n",
       " 'city',\n",
       " \"'s\",\n",
       " 'climate',\n",
       " 'to',\n",
       " 'stay',\n",
       " 'warm',\n",
       " 'and',\n",
       " 'mild',\n",
       " 'all',\n",
       " 'year',\n",
       " '<',\n",
       " 'eos',\n",
       " '>']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_field.preprocess(ans_field.init_token+\" \"+sent+\" \"+ans_field.eos_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos>'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0886932644057201"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"eval_results.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[[\"Target Question\",\"Predited Question\"]]\n",
    "def to_list(x):\n",
    "    return [x]\n",
    "df[\"Target Question\"]=df[\"Target Question\"].apply(to_list)\n",
    "df[\"Predited Question\"]=df[\"Predited Question\"].apply(to_list)\n",
    "\n",
    "x=df.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "gts=x[\"Target Question\"]\n",
    "res=x[\"Predited Question\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocoevalcap.bleu import bleu\n",
    "from pycocoevalcap.meteor import meteor\n",
    "from pycocoevalcap.cider import cider\n",
    "from pycocoevalcap.rouge import rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=bleu.Bleu()\n",
    "b=meteor.Meteor()\n",
    "c=cider.Cider()\n",
    "d=rouge.Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'testlen': 105593, 'reflen': 131500, 'guess': [105593, 92873, 80153, 67436], 'correct': [33395, 7870, 2260, 672]}\n",
      "ratio: 0.8029885931558874\n"
     ]
    }
   ],
   "source": [
    "bleu=a.compute_score(gts,res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteor=b.compute_score(gts,res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "cider=c.compute_score(gts,res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge=d.compute_score(gts,res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.24745325190851894,\n",
       " 0.12808923589788326,\n",
       " 0.07126674516206394,\n",
       " 0.040987013306830765]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09669906757901764"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meteor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4124199744563699"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cider[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2530183794252212"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
